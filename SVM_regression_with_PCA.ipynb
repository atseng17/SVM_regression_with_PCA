{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM regression with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we are going to understand whta is SVM and PCA. These concepts are both inportand and have different uses seperately. However people are often confused by the two, today we use a simple example to clarify the differene between the two concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "data = pd.read_csv(\"./input/diabetes.csv\")\n",
    "print(data.shape)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  \n",
      "0                     0.627   50  \n",
      "1                     0.351   31  \n",
      "--------\n",
      "0    1\n",
      "1    0\n",
      "Name: Outcome, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "features=data.iloc[:,:-1]\n",
    "labels=data.iloc[:,-1]\n",
    "print(features.head(2))\n",
    "print('--------')\n",
    "print(labels.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priciple component analysis (PCA) \n",
    "PCA is a way to reduce the dimentionality of the system while capturing the features that represents the original system.\n",
    "\n",
    "source: \n",
    "https://www.youtube.com/watch?v=MrtPbruYbWY&fbclid=IwAR3Swm01tc6MPM95ftGjY8fgU9r5CIy82bQwvoIbdjQj4onHNTbUJWRsn6w\n",
    "\n",
    "https://www.kaggle.com/uciml/pima-indians-diabetes-database/downloads/diabetes.csv/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26608124, 0.2125024 , 0.1292791 , 0.10800322, 0.09565838,\n",
       "       0.08606059, 0.05414537, 0.0482697 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test train split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(features,labels,test_size=0.2)\n",
    "\n",
    "#Standard scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#Applying PCA here\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components= None) #We will set it none so that we can see the variance explained and then choose no of comp.\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have maped the original feature data to a new feature set with a linear transform. the number of features reamins unchanged. From the scores, listed in the array, we could choose the first n values so that our feature numbers are reduced to n features. Note that the reduced features are no longer the original features, because they have gone through a linear transformation.\n",
    "\n",
    "Let's see compare the performance of a logistic regression model using the original features and the reduced features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[92 11]\n",
      " [19 32]]\n",
      "[[86 17]\n",
      " [29 22]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Without PCA\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(features,labels,test_size=0.2)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_pred)#Compute confusion matrix\n",
    "print(cm)\n",
    "\n",
    "# PCA\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(features,labels,test_size=0.2)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components= 2)\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "\n",
    "\n",
    "classifier = LogisticRegression(random_state=0)# Create the classifier and train using training data\n",
    "classifier.fit(X_train_reduced,y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_reduced)#Predict the test set values\n",
    "\n",
    "cm_r = confusion_matrix(y_test,y_pred)#Compute confusion matrix\n",
    "print(cm_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is seen that there is no significant changes between the two feature sets(original and the linearly transformed and reduced version), which means that we have successfully reduced the dimentionality of the feature set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n",
    "SVM is a technique to find the best fit for the data points. Yet, this is not the only features of SVM. SVM also includes a a kernel which performs nonlinear tranform to the data points. On can say that with these kernels, the features are mapped to a higher dimention. To summerize, svm does not do any dimentional reduction, it further maps the original features to a higher dimention.\n",
    "\n",
    "Source:\n",
    "https://www.youtube.com/watch?v=Y6RRHw9uN9o&fbclid=IwAR2Z7_pkuJhxmSXcBvl9wwXrOai3bLkyg5xtY0GzMeQDH4lvrFgWnTZLiHI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression\n",
    "Instead of trying to fit the largest possible gab between the two classes while limiting marginal violations, Support Vector Regression tries to fit as many istances as possible between the gap.\n",
    "\n",
    "Source:\n",
    "https://www.youtube.com/watch?v=IcCZaA7zITc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77, 18],\n",
       "       [26, 33]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(features,labels,test_size=0.2)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#Create classifier object\n",
    "from sklearn.svm import SVC\n",
    "classifier_svm_kernel = SVC(C=5.0,kernel='rbf', gamma=0.12,tol=0.00001)\n",
    "classifier_svm_kernel.fit(X_train,y_train)\n",
    "\n",
    "#Predict the result for test values\n",
    "y_pred = classifier_svm_kernel.predict(X_test)\n",
    "\n",
    "#Compute confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying grid search for optimal parameters and model after k-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7817589576547231\n",
      "{'C': 10, 'gamma': 0.125, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = [{'C':[0.01,0.1,1,10,50,100,500,1000], \\\n",
    "               'kernel':['rbf'], \\\n",
    "               'gamma': [0.1,0.125,0.15,0.17,0.2]}]\n",
    "grid_search = GridSearchCV(estimator=classifier_svm_kernel, \\\n",
    "                           param_grid=parameters, \\\n",
    "                           scoring ='accuracy',\\\n",
    "                           cv=10,n_jobs=-1)\n",
    "grid_search = grid_search.fit(X_train,y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_\n",
    "opt_param = grid_search.best_params_\n",
    "\n",
    "print(best_accuracy)\n",
    "print(opt_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the optimised hyperparameters to retrain the model with original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[91, 13],\n",
       "       [22, 28]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(features,labels,test_size=0.2)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#Create classifier object\n",
    "from sklearn.svm import SVC\n",
    "classifier_svm_kernel = SVC(C=10.0,kernel='rbf', gamma=0.125,tol=0.00001)\n",
    "classifier_svm_kernel.fit(X_train,y_train)\n",
    "\n",
    "#Predict the result for test values\n",
    "y_pred = classifier_svm_kernel.predict(X_test)\n",
    "\n",
    "#Compute confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do have a better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[99, 13],\n",
       "       [22, 20]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(features,labels,test_size=0.2)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components= 2)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "\n",
    "#Create classifier object\n",
    "from sklearn.svm import SVC\n",
    "classifier_svm_kernel = SVC(C=10.0,kernel='rbf', gamma=0.125,tol=0.00001)\n",
    "classifier_svm_kernel.fit(X_train,y_train)\n",
    "\n",
    "#Predict the result for test values\n",
    "y_pred = classifier_svm_kernel.predict(X_test)\n",
    "\n",
    "#Compute confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, isnt it amazing, using only two components, we achieved a really similar performance. By only using two features, we are able to save a lot of time on computations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
